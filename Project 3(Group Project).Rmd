---
title: "Project 3 (Group)"
author: "Team A1"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# You will need to determine what tool(s) you’ll use as a group to effectively collaborate, share code and any project documentation (such as motivation, approach, findings). 

# You will have to determine what data to collect, where the data can be found, and how to load it. 

# The data that you decide to collect should reside in a relational database, in a set of normalized tables. 

# You should perform any needed tidying, transformations, and exploratory data analysis in R. 

# Your deliverable should include all code, results, and documentation of your motivation, approach, and findings. 

# As a group, you should appoint (at least) three people to lead parts of the presentation. 

# While you are strongly encouraged (and will hopefully find it fun) to try out statistics and data models, your grade will not be affected by the statistical analysis and modeling performed (since this is a semester one course on Data Acquisition and Management). 

# Every student must be prepared to explain how the data was collected, loaded, transformed, tidied, and analyzed for outliers, etc. in our Meetup.  This is the only way I’ll have to determine that everyone actively participated in the process, so you need to hold yourself responsible for understanding what your class-size team did!  If you are unable to attend the meet up, then you need to either present to me one-on-one before the meetup presentation, or post a 3 to 5 minute video (e.g. on YouTube) explaining the process.  Individual students will not be responsible for explaining any forays into statistical analysis, modeling, data mining, regression, decision trees, etc. 



# Introduction: This is a group project of team A1. We are four members including Mohammad Zahid Chowdhury, Stefan Huber, Tyler Graham and Daniel DeBonis in this group. 


# Effective Collaboration tools: In the data science field, for communication and documentation purposes we have maintained the following tools. 

# Communication:

      ##  Discord and Zoom


# Code Sharing:

      ##  Github


# Project Documentation: 


    ##  Draw.io – ER diagram 
	  ##  RStudio – writing code or data processing 
    ##  Word document- Documenting work done
    ##  Power Point - For Presentation the group project


# Data Sources and Management:
	
# Data is collected from https://www.kaggle.com/datasets/misganawtboltana/data-science-job-market-in-2025-15k. And save this data as CSV file and uploaded it in GitHub.File is available in github link.  


# Required Packages installation and loading:

```{r}

install.packages("tidyverse")
library(tidyverse)


```


# Data Loading and reading:


```{r}

project3_data<-read.csv("https://raw.githubusercontent.com/zahid607/Project-3/refs/heads/main/Data%20Science_Jobs%20.csv")

head(project3_data)

View(project3_data)

```


# Data Cleaning:

```{r}
# Check for missing values

summary(project3_data)

# Check the structure of the data
str(project3_data)

# Check for any NA values
sum(is.na(project3_data))

# Clean data (if necessary)
# For example, removing rows with missing values:
data_clean <- na.omit(project3_data)

```


# Data transformation:




